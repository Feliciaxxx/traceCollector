// file: processor/tailsamplingprocessor/processor.go

// SPDX-License-Identifier: Apache-2.0

// file: processor/tailsamplingprocessor/processor.go

// SPDX-License-Identifier: Apache-2.0

package tailsamplingprocessor

import (
	"context"
	"math"
	"math/rand"
	"sort"
	"sync"

	"go.opentelemetry.io/collector/component"
	"go.opentelemetry.io/collector/consumer"
	"go.opentelemetry.io/collector/pdata/ptrace"
	"go.opentelemetry.io/collector/processor"
	"go.uber.org/zap"

	"github.com/samplingCollector/tailsamplingprocessor/internal/tracepicker"
)

type tailSamplingSpanProcessor struct {
	ctx          context.Context
	set          processor.Settings
	logger       *zap.Logger
	nextConsumer consumer.Traces
	config       Config
	buffer       *tracepicker.SharedBuffer
	encoder      *tracepicker.BFSEncoder
	pathCounter  sync.Map
}

func newTracesProcessor(
	ctx context.Context,
	set processor.Settings,
	nextConsumer consumer.Traces,
	cfg Config,
) (processor.Traces, error) {
	// ... æ„é€ å‡½æ•°ä¿æŒä¸å˜ ...
	histPool := tracepicker.NewHistPool(cfg.PoolHeight)
	encoder := tracepicker.NewBFSEncoder(histPool)
	buffer := tracepicker.NewSharedBuffer(cfg.BufferSize)

	tsp := &tailSamplingSpanProcessor{
		ctx:          ctx,
		set:          set,
		logger:       set.Logger,
		nextConsumer: nextConsumer,
		config:       cfg,
		buffer:       buffer,
		encoder:      encoder,
	}

	return tsp, nil
}

// NewTracesProcessor åˆ›å»ºä¸€ä¸ªæ–°çš„ tail sampling processor (å¯¼å‡ºå‡½æ•°ç”¨äºæµ‹è¯•)
func NewTracesProcessor(
	ctx context.Context,
	set processor.Settings,
	nextConsumer consumer.Traces,
	cfg Config,
) (processor.Traces, error) {
	return newTracesProcessor(ctx, set, nextConsumer, cfg)
}

// ã€æ ¸å¿ƒå˜æ›´ã€‘ConsumeTraces ç°åœ¨æ˜¯éé˜»å¡çš„
func (tsp *tailSamplingSpanProcessor) ConsumeTraces(_ context.Context, td ptrace.Traces) error {
	typeID, isAbnormal := tsp.encoder.Encode(td)
	tsp.buffer.Add(typeID, td, isAbnormal)

	// ç®€åŒ–çš„æ—¥å¿—ï¼Œåªåœ¨ç¼“å†²åŒºçŠ¶æ€å˜åŒ–æ—¶è¾“å‡º
	bufferCount := tsp.buffer.Count()
	if bufferCount%10 == 0 || tsp.buffer.IsFull() {
		tsp.logger.Info("Buffer status",
			zap.Uint64("count", bufferCount),
			zap.Uint64("limit", tsp.config.BufferSize),
			zap.Bool("full", tsp.buffer.IsFull()))
	}

	if tsp.buffer.IsFull() {
		tsp.logger.Info("ğŸ¯ Buffer full, triggering tail sampling",
			zap.Uint64("traces", bufferCount))
		// 1. åŸå­åœ°æ¢å‡ºæ•°æ®å‰¯æœ¬å¹¶æ¸…ç©ºåŸç¼“å†²åŒº
		normalTraces, abnormalTraces, count := tsp.buffer.SwapAndClear()

		// 2. å°†è€—æ—¶çš„é‡‡æ ·å·¥ä½œæ”¾åˆ°åå°goroutineä¸­æ‰§è¡Œï¼Œè®©ConsumeTracesç«‹åˆ»è¿”å›
		go tsp.runBatchSampling(normalTraces, abnormalTraces, count)
	}
	return nil
}

// ã€æ ¸å¿ƒå˜æ›´ã€‘runBatchSampling ç°åœ¨æ¥æ”¶æ•°æ®å‰¯æœ¬ä½œä¸ºå‚æ•°
func (tsp *tailSamplingSpanProcessor) runBatchSampling(
	normalTracesByType map[string][]ptrace.Traces,
	abnormalTraces []ptrace.Traces,
	bufferCount uint64,
) {
	tsp.logger.Info("ğŸ”¬ Starting tail sampling analysis...",
		zap.Uint64("total_traces", bufferCount),
		zap.Int("abnormal_traces", len(abnormalTraces)),
		zap.Int("normal_trace_types", len(normalTracesByType)))

	// 1. ä¼˜å…ˆä¿ç•™æ‰€æœ‰å¼‚å¸¸è¿½è¸ª
	finalSampledTraces := make([]ptrace.Traces, 0, bufferCount)
	finalSampledTraces = append(finalSampledTraces, abnormalTraces...)

	// 2. è®¡ç®—å‰©ä½™é‡‡æ ·é…é¢
	totalSampleCount := int(float64(bufferCount) * tsp.config.SampleRate)
	currentQuota := totalSampleCount - len(finalSampledTraces)

	tsp.logger.Info("ğŸ“Š Sampling calculation",
		zap.Int("target_sample_count", totalSampleCount),
		zap.Int("abnormal_kept", len(abnormalTraces)),
		zap.Int("remaining_quota", currentQuota))

	if currentQuota > 0 && len(normalTracesByType) > 0 {
		// 3. å‡†å¤‡é…é¢åˆ†é…çš„è¾“å…¥æ•°æ®
		typeCounts := make(map[string]int)
		for code, traces := range normalTracesByType {
			typeCounts[code] = len(traces)
		}

		historicalCounts := make(map[string]int)
		tsp.pathCounter.Range(func(key, value interface{}) bool {
			historicalCounts[key.(string)] = value.(int)
			return true
		})

		quotaMap := tracepicker.AllocateQuota(typeCounts, historicalCounts, currentQuota)

		// 4. è°ƒç”¨æ¼”åŒ–ç®—æ³•è¿›è¡Œåˆ†ç»„é‡‡æ ·
		// (æ•°æ®å‡†å¤‡éƒ¨åˆ†é€»è¾‘ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ)
		allLabels, label2idx := getAllLabelsAndMap(normalTracesByType, abnormalTraces)
		var sortedTypes []string
		for typeID := range normalTracesByType {
			sortedTypes = append(sortedTypes, typeID)
		}
		sort.Strings(sortedTypes)

		var quotas, bases []int
		var allNormalTraces []ptrace.Traces
		for _, typeID := range sortedTypes {
			traces := normalTracesByType[typeID]
			bases = append(bases, len(traces))
			allNormalTraces = append(allNormalTraces, traces...)
			quotas = append(quotas, quotaMap[typeID])
		}

		rawDist := buildLatencyMatrix(allNormalTraces, label2idx, allLabels)
		abDist := buildLatencyMatrix(abnormalTraces, label2idx, allLabels)

		problem, err := tracepicker.NewSampleProblem(rawDist, abDist, quotas, bases, tsp.config.CombinationCount, 1)
		if err != nil {
			tsp.logger.Error("Failed to create sample problem", zap.Error(err))
			return
		}

		// ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬çš„ä¼˜åŒ–å™¨
		optimizerSimple := tracepicker.NewSampleOptimizerSimple(problem)
		bestSimple, err := optimizerSimple.OptimizeWithSimpleFallback()
		if err != nil {
			tsp.logger.Warn("Simple genetic algorithm optimization failed, trying advanced version",
				zap.Error(err))

			// å°è¯•é«˜çº§ç‰ˆæœ¬
			advancedProblem, err := tracepicker.ConvertToSampleProblemAdvanced(problem, tsp.config.CombinationCount)
			if err != nil {
				tsp.logger.Warn("Failed to convert to advanced problem, using simple random sampling",
					zap.Error(err))

				// å›é€€åˆ°ç®€å•éšæœºé‡‡æ ·
				finalSampledTraces = tsp.simpleRandomSampling(allNormalTraces, abnormalTraces, int(bufferCount))
			} else {
				// ä½¿ç”¨é«˜çº§ç‰ˆæœ¬çš„ä¼˜åŒ–å™¨
				optimizerAdvanced := tracepicker.NewSampleOptimizerAdvanced(advancedProblem)
				bestAdvanced, err := optimizerAdvanced.OptimizeWithAdvancedFallback()
				if err != nil {
					tsp.logger.Warn("Advanced genetic algorithm optimization failed, falling back to simple random sampling",
						zap.Error(err))

					// å›é€€åˆ°ç®€å•éšæœºé‡‡æ ·
					finalSampledTraces = tsp.simpleRandomSampling(allNormalTraces, abnormalTraces, int(bufferCount))
				} else {
					// 5. æ ¹æ®é«˜çº§ä¼˜åŒ–ç»“æœè·å–æœ€ç»ˆè¦é‡‡æ ·çš„è¿½è¸ª
					finalIndices := advancedProblem.GetIdxsByVar(bestAdvanced.Genes)
					for _, idx := range finalIndices {
						if idx < len(allNormalTraces) {
							finalSampledTraces = append(finalSampledTraces, allNormalTraces[idx])
						}
					}
				}
			}
		} else {
			// 5. æ ¹æ®ä¼˜åŒ–ç»“æœè·å–æœ€ç»ˆè¦é‡‡æ ·çš„è¿½è¸ª
			finalIndices := problem.GetIdxsByVar(bestSimple.Genes)
			for _, idx := range finalIndices {
				if idx < len(allNormalTraces) {
					finalSampledTraces = append(finalSampledTraces, allNormalTraces[idx])
				}
			}

			// 6. æ›´æ–°å†å²é‡‡æ ·è®¡æ•°
			sampledCountByType := make(map[string]int)
			for _, idx := range finalIndices {
				if idx < len(allNormalTraces) {
					typeID, _ := tsp.encoder.Encode(allNormalTraces[idx])
					sampledCountByType[typeID]++
				}
			}
			for typeID, count := range sampledCountByType {
				c, _ := tsp.pathCounter.LoadOrStore(typeID, 0)
				tsp.pathCounter.Store(typeID, c.(int)+count)
			}
		}
	}

	// 7. å°†æœ€ç»ˆé‡‡æ ·çš„è¿½è¸ªæ•°æ®å‘é€ç»™ä¸‹æ¸¸æ¶ˆè´¹è€…
	tsp.exportTraces(finalSampledTraces)

	// è®¡ç®—é‡‡æ ·ç»Ÿè®¡
	samplingRate := float64(len(finalSampledTraces)) / float64(bufferCount) * 100
	tsp.logger.Info("âœ… Tail sampling completed",
		zap.Int("input_traces", int(bufferCount)),
		zap.Int("output_traces", len(finalSampledTraces)),
		zap.Float64("actual_sampling_rate", samplingRate))
}

// exportTraces è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜ã€‚
func (tsp *tailSamplingSpanProcessor) exportTraces(traces []ptrace.Traces) {
	for _, td := range traces {
		if err := tsp.nextConsumer.ConsumeTraces(tsp.ctx, td); err != nil {
			tsp.logger.Error("Failed to send traces to next consumer", zap.Error(err))
		}
	}
}

// --- ç»„ä»¶ç”Ÿå‘½å‘¨æœŸæ–¹æ³• ---

func (tsp *tailSamplingSpanProcessor) Capabilities() consumer.Capabilities {
	return consumer.Capabilities{MutatesData: false}
}

func (tsp *tailSamplingSpanProcessor) Start(_ context.Context, _ component.Host) error {
	return nil
}

func (tsp *tailSamplingSpanProcessor) Shutdown(_ context.Context) error {
	tsp.logger.Info("Processor is shutting down, processing remaining traces in the buffer...")
	// åœ¨å…³é—­æ—¶ï¼ŒåŒæ­¥å¤„ç†æœ€åä¸€æ‰¹æ•°æ®
	normalTraces, abnormalTraces, count := tsp.buffer.SwapAndClear()
	if count > 0 {
		tsp.logger.Info("Processing remaining traces during shutdown", zap.Uint64("count", count))
		tsp.runBatchSampling(normalTraces, abnormalTraces, count)
	}
	return nil
}

// è¾…åŠ©å‡½æ•°
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// --- æ–°å¢çš„è¾…åŠ©å‡½æ•° ---

// getSpanLabel ä» span ä¸­æå– "service:operation" æ ‡ç­¾ã€‚
func getSpanLabel(span ptrace.Span) string {
	serviceName := "unknown.service"
	if val, ok := span.Attributes().Get("service.name"); ok {
		serviceName = val.Str()
	}
	return serviceName + ":" + span.Name()
}

// getAllLabelsAndMap éå†æ‰€æœ‰è¿½è¸ªï¼Œè·å–å”¯ä¸€çš„æ ‡ç­¾åˆ—è¡¨å’Œæ ‡ç­¾åˆ°ç´¢å¼•çš„æ˜ å°„ã€‚
func getAllLabelsAndMap(normalTraces map[string][]ptrace.Traces, abnormalTraces []ptrace.Traces) ([]string, map[string]int) {
	labelSet := make(map[string]struct{})
	for _, traces := range normalTraces {
		for _, trace := range traces {
			rs := trace.ResourceSpans()
			for i := 0; i < rs.Len(); i++ {
				ils := rs.At(i).ScopeSpans()
				for j := 0; j < ils.Len(); j++ {
					spans := ils.At(j).Spans()
					for k := 0; k < spans.Len(); k++ {
						labelSet[getSpanLabel(spans.At(k))] = struct{}{}
					}
				}
			}
		}
	}
	// (åŒæ ·é€»è¾‘éå† abnormalTraces)

	labels := make([]string, 0, len(labelSet))
	for label := range labelSet {
		labels = append(labels, label)
	}
	sort.Strings(labels)

	label2idx := make(map[string]int, len(labels))
	for i, label := range labels {
		label2idx[label] = i
	}
	return labels, label2idx
}

// buildLatencyMatrix å°†è¿½è¸ªåˆ—è¡¨è½¬æ¢ä¸ºä¼˜åŒ–å™¨æ‰€éœ€çš„å»¶è¿ŸçŸ©é˜µã€‚
func buildLatencyMatrix(traces []ptrace.Traces, label2idx map[string]int, allLabels []string) [][]float64 {
	matrix := make([][]float64, len(traces))
	for i, trace := range traces {
		latencies := make([]float64, len(allLabels))
		for j := range latencies {
			latencies[j] = math.NaN() // é»˜è®¤å€¼ä¸º NaN
		}

		rs := trace.ResourceSpans()
		for j := 0; j < rs.Len(); j++ {
			ils := rs.At(j).ScopeSpans()
			for k := 0; k < ils.Len(); k++ {
				spans := ils.At(k).Spans()
				for l := 0; l < spans.Len(); l++ {
					span := spans.At(l)
					label := getSpanLabel(span)
					if idx, ok := label2idx[label]; ok {
						duration := span.EndTimestamp().AsTime().Sub(span.StartTimestamp().AsTime())
						latencies[idx] = float64(duration.Milliseconds())
					}
				}
			}
		}
		matrix[i] = latencies
	}
	return matrix
}

// simpleRandomSampling å®ç°ç®€å•çš„éšæœºé‡‡æ ·ä½œä¸ºå›é€€æ–¹æ¡ˆ
func (tsp *tailSamplingSpanProcessor) simpleRandomSampling(normalTraces, abnormalTraces []ptrace.Traces, totalTraces int) []ptrace.Traces {
	// è®¡ç®—é‡‡æ ·æ•°é‡
	sampleCount := int(float64(totalTraces) * tsp.config.SampleRate)
	if sampleCount <= 0 {
		return []ptrace.Traces{}
	}

	var allTraces []ptrace.Traces
	allTraces = append(allTraces, normalTraces...)
	allTraces = append(allTraces, abnormalTraces...)

	// å¦‚æœæ€»æ•°ä¸è¶³é‡‡æ ·æ•°é‡ï¼Œè¿”å›å…¨éƒ¨
	if len(allTraces) <= sampleCount {
		tsp.logger.Info("Total traces less than sample count, returning all traces",
			zap.Int("total_traces", len(allTraces)),
			zap.Int("sample_count", sampleCount))
		return allTraces
	}

	// éšæœºé‡‡æ ·
	indices := make([]int, len(allTraces))
	for i := range indices {
		indices[i] = i
	}

	// Fisher-Yates shuffle
	for i := len(indices) - 1; i > 0; i-- {
		j := rand.Intn(i + 1)
		indices[i], indices[j] = indices[j], indices[i]
	}

	// å–å‰ sampleCount ä¸ª
	result := make([]ptrace.Traces, sampleCount)
	for i := 0; i < sampleCount; i++ {
		result[i] = allTraces[indices[i]]
	}

	tsp.logger.Info("âœ… Simple random sampling completed",
		zap.Int("input_traces", len(allTraces)),
		zap.Int("output_traces", len(result)),
		zap.Float64("sampling_rate", float64(len(result))/float64(len(allTraces))*100))

	return result
}
