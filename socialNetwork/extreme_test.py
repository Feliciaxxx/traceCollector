#!/usr/bin/env python3
import requests
import json
import time
import random
import threading
import concurrent.futures

# OTLP HTTP endpoint for our custom collector
COLLECTOR_URL = "http://localhost:8326/v1/traces"

def generate_extreme_trace(trace_id, span_count=15):
    """ç”Ÿæˆæžç«¯å¤æ‚çš„æµ‹è¯•traceæ•°æ®æ¥å¼ºåˆ¶è§¦å‘é«˜çº§é—ä¼ ç®—æ³•"""
    spans = []
    base_time = int(time.time() * 1_000_000_000)  # nanoseconds
    
    # æžç«¯å¤šæ ·åŒ–çš„æœåŠ¡ç±»åž‹
    service_types = [
        "auth", "payment", "inventory", "recommendation", "social-graph", 
        "timeline", "notification", "analytics", "billing", "fraud-detection",
        "content-delivery", "search", "ml-inference", "data-pipeline",
        "user-profile", "messaging", "file-storage", "video-processing",
        "real-time-chat", "recommendation-engine", "ad-targeting"
    ]
    
    # æžç«¯çš„é”™è¯¯çŽ‡åˆ†å¸ƒ
    error_rates = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.8]
    
    # æžç«¯çš„å»¶è¿Ÿåˆ†å¸ƒ
    latencies = [
        (1_000_000, 10_000_000),      # è¶…å¿« 1-10ms
        (10_000_000, 50_000_000),     # å¿«é€Ÿ 10-50ms
        (50_000_000, 200_000_000),    # ä¸­ç­‰ 50-200ms  
        (200_000_000, 1_000_000_000), # æ…¢é€Ÿ 200ms-1s
        (1_000_000_000, 5_000_000_000), # å¾ˆæ…¢ 1-5s
        (5_000_000_000, 15_000_000_000) # æžæ…¢ 5-15s
    ]
    
    for i in range(span_count):
        span_id = f"{i+1:016x}"
        service_type = random.choice(service_types)
        error_rate = random.choice(error_rates)
        latency_range = random.choice(latencies)
        duration = random.randint(latency_range[0], latency_range[1])
        
        # æžç«¯çš„çŠ¶æ€ç åˆ†å¸ƒ
        if error_rate > 0.3:
            status_code = random.choice([1, 2, 2, 2])  # é«˜é”™è¯¯çŽ‡
        elif error_rate > 0.1:
            status_code = random.choice([0, 0, 1, 2])  # ä¸­é”™è¯¯çŽ‡
        else:
            status_code = random.choice([0, 0, 0, 0, 0, 0, 0, 1])  # ä½Žé”™è¯¯çŽ‡
        
        span = {
            "traceId": trace_id,
            "spanId": span_id,
            "name": f"{service_type}-extreme-operation-{i+1}",
            "kind": random.choice([1, 2, 3, 4, 5]),  # æ‰€æœ‰spanç±»åž‹
            "startTimeUnixNano": str(base_time + i * 1_000_000),
            "endTimeUnixNano": str(base_time + i * 1_000_000 + duration),
            "attributes": [
                {"key": "service.name", "value": {"stringValue": f"{service_type}-extreme-service"}},
                {"key": "latency.ms", "value": {"doubleValue": duration / 1_000_000}},
                {"key": "error.rate", "value": {"doubleValue": error_rate}},
                {"key": "throughput", "value": {"doubleValue": random.uniform(1, 50000)}},
                {"key": "cpu.usage", "value": {"doubleValue": random.uniform(0.01, 0.99)}},
                {"key": "memory.usage", "value": {"doubleValue": random.uniform(0.05, 0.95)}},
                {"key": "operation.complexity", "value": {"intValue": random.randint(1, 20)}},
                {"key": "data.size.mb", "value": {"doubleValue": random.uniform(0.1, 1000)}},
                {"key": "network.latency.ms", "value": {"doubleValue": random.uniform(1, 500)}},
                {"key": "db.connections", "value": {"intValue": random.randint(1, 100)}},
                {"key": "cache.hit.ratio", "value": {"doubleValue": random.uniform(0.1, 0.9)}},
                {"key": "concurrent.users", "value": {"intValue": random.randint(1, 10000)}},
                {"key": "request.size.kb", "value": {"doubleValue": random.uniform(0.5, 10000)}},
                {"key": "response.size.kb", "value": {"doubleValue": random.uniform(0.1, 50000)}},
                {"key": "security.threat.level", "value": {"intValue": random.randint(0, 5)}}
            ],
            "status": {"code": status_code}
        }
        
        # å¤æ‚çš„çˆ¶å­å…³ç³»
        if i > 0:
            if i == 1:
                span["parentSpanId"] = f"{1:016x}"
            elif i <= 3:
                span["parentSpanId"] = f"{random.randint(1, i):016x}"
            else:
                span["parentSpanId"] = f"{random.randint(max(1, i-3), i):016x}"
            
        spans.append(span)
    
    return {
        "resourceSpans": [{
            "resource": {
                "attributes": [
                    {"key": "service.name", "value": {"stringValue": f"extreme-microservice-{random.randint(1,10)}"}},
                    {"key": "service.version", "value": {"stringValue": f"3.{random.randint(0,9)}.{random.randint(0,9)}"}},
                    {"key": "deployment.environment", "value": {"stringValue": random.choice(["prod", "staging", "dev", "test", "canary"])}},
                    {"key": "datacenter", "value": {"stringValue": random.choice(["us-east-1", "us-west-2", "eu-west-1", "ap-south-1"])}},
                    {"key": "cluster.id", "value": {"stringValue": f"cluster-{random.randint(1,20)}"}},
                    {"key": "node.id", "value": {"stringValue": f"node-{random.randint(1,100)}"}}
                ]
            },
            "scopeSpans": [{
                "scope": {"name": "extreme-test-scope-v2"},
                "spans": spans
            }]
        }]
    }

def extreme_stress_test():
    """æžç«¯åŽ‹åŠ›æµ‹è¯•ï¼Œå¼ºåˆ¶è§¦å‘é«˜çº§é—ä¼ ç®—æ³•"""
    print("ðŸ§¬ðŸ”¥ å¼€å§‹æžç«¯åŽ‹åŠ›æµ‹è¯• - å¼ºåˆ¶è§¦å‘é«˜çº§é—ä¼ ç®—æ³•...")
    print("ç›®æ ‡ï¼šäº§ç”Ÿè¶³å¤Ÿå¤æ‚çš„æ•°æ®ä½¿ç®€å•ç®—æ³•å¤±è´¥ï¼Œä»Žè€Œè§¦å‘é«˜çº§ç®—æ³•")
    print("="*80)
    
    batch_size = 8  # æ¯æ‰¹8ä¸ªtracesä»¥å¿«é€Ÿå¡«æ»¡buffer
    total_batches = 50  # æ€»å…±400ä¸ªæžç«¯å¤æ‚çš„traces
    
    def send_extreme_batch(batch_id):
        print(f"ðŸš€ æ‰¹æ¬¡ {batch_id}: å‘é€æžç«¯å¤æ‚traces...")
        
        for trace_num in range(batch_size):
            trace_id = f"{batch_id:04x}{trace_num+1:028x}"
            span_count = random.randint(10, 20)  # å¤§é‡spanså¢žåŠ å¤æ‚æ€§
            
            trace_data = generate_extreme_trace(trace_id, span_count)
            
            try:
                response = requests.post(
                    COLLECTOR_URL,
                    json=trace_data,
                    headers={"Content-Type": "application/json"},
                    timeout=10
                )
                
                if response.status_code == 200:
                    print(f"  âœ… æžç«¯Trace{trace_num+1}: {span_count} spans")
                else:
                    print(f"  âŒ æžç«¯Trace{trace_num+1}: {response.status_code}")
                    
            except Exception as e:
                print(f"  âŒ æžç«¯Trace{trace_num+1}: {e}")
        
        time.sleep(0.5)  # æ‰¹æ¬¡é—´éš”
    
    # ä½¿ç”¨å¤šçº¿ç¨‹å¿«é€Ÿå‘é€
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        futures = []
        
        for batch_id in range(1, total_batches + 1):
            future = executor.submit(send_extreme_batch, batch_id)
            futures.append(future)
            time.sleep(0.1)  # å¿«é€Ÿå‘é€ä»¥å¡«æ»¡buffer
        
        # ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
        for future in concurrent.futures.as_completed(futures):
            try:
                future.result()
            except Exception as e:
                print(f"æ‰¹æ¬¡å¤„ç†é”™è¯¯: {e}")
    
    print("="*80)
    print("ðŸŽ¯ æžç«¯åŽ‹åŠ›æµ‹è¯•å®Œæˆï¼")
    print(f"ðŸ“Š å·²å‘é€ {total_batches * batch_size} ä¸ªè¶…å¤æ‚traces")
    print("ðŸ”¬ åº”è¯¥å·²ç»è§¦å‘é«˜çº§é—ä¼ ç®—æ³•çš„RMSEã€ç™¾åˆ†ä½æ•°åˆ†æžç­‰åŠŸèƒ½")
    print("ðŸ“ æ£€æŸ¥collectoræ—¥å¿—æŸ¥çœ‹è¯¦ç»†çš„é«˜çº§ç®—æ³•æ‰§è¡Œç»“æžœ...")

if __name__ == "__main__":
    extreme_stress_test()
